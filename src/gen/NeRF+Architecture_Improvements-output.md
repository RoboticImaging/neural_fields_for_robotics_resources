<span class="csl-left-margin">\[1\] </span><span
class="csl-right-inline">Z. Kuang, K. Olszewski, M. Chai, Z. Huang, P.
Achlioptas, and S. Tulyakov, “NeROIC: Neural object capture and
rendering from online image collections,” *Computing Research Repository
(CoRR)*, vol. abs/2201.02533, 2022. </span>

<span class="csl-left-margin">\[2\] </span><span
class="csl-right-inline">F. Wimbauer, S. Wu, and C. Rupprecht,
“De-rendering 3D Objects in the Wild,” *arXiv:2201.02279 \[cs\]*, Jan.
2022 \[Online\]. Available: <http://arxiv.org/abs/2201.02279>.
\[Accessed: Jan. 23, 2022\]</span>

<span class="csl-left-margin">\[3\] </span><span
class="csl-right-inline">M. Kim, S. Seo, and B. Han, “InfoNeRF: Ray
Entropy Minimization for Few-Shot Neural Volume Rendering,”
*arXiv:2112.15399 \[cs, eess\]*, Dec. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2112.15399>. \[Accessed: Jan. 23, 2022\]</span>

<span class="csl-left-margin">\[4\] </span><span
class="csl-right-inline">C. C. Yoonwoo Jeong Seokjun Ahn and J. Park,
“Self-Calibrating Neural Radiance Fields,” in *ICCV*, 2021. </span>

<span class="csl-left-margin">\[5\] </span><span
class="csl-right-inline">Y. Xiangli *et al.*, “CityNeRF: Building NeRF
at City Scale,” *arXiv preprint arXiv:2112.05504*, 2021. </span>

<span class="csl-left-margin">\[6\] </span><span
class="csl-right-inline">M. Tancik *et al.*, “Block-NeRF: Scalable Large
Scene Neural View Synthesis,” *arXiv*, 2022. </span>

<span class="csl-left-margin">\[7\] </span><span
class="csl-right-inline">K. Rematas, R. Martin-Brualla, and V. Ferrari,
“ShaRF: Shape-conditioned Radiance Fields from a Single View.” 2021.
</span>

<span class="csl-left-margin">\[8\] </span><span
class="csl-right-inline">B. Kaya, S. Kumar, F. Sarno, V. Ferrari, and L.
V. Gool, “Neural Radiance Fields Approach to Deep Multi-View Photometric
Stereo.” 2021. </span>

<span class="csl-left-margin">\[9\] </span><span
class="csl-right-inline">Q. Xu *et al.*, “Point-NeRF: Point-based Neural
Radiance Fields,” *arXiv preprint arXiv:2201.08845*, 2022. </span>

<span class="csl-left-margin">\[10\] </span><span
class="csl-right-inline">C. Xie, K. Park, R. Martin-Brualla, and M.
Brown, “FiG-NeRF: Figure-Ground Neural Radiance Fields for 3D Object
Category Modelling,” *arXiv:2104.08418 \[cs\]*, Apr. 2021 \[Online\].
Available: <http://arxiv.org/abs/2104.08418>. \[Accessed: Sep. 25,
2021\]</span>

<span class="csl-left-margin">\[11\] </span><span
class="csl-right-inline">A. Yu, R. Li, M. Tancik, H. Li, R. Ng, and A.
Kanazawa, “PlenOctrees for Real-time Rendering of Neural Radiance
Fields,” *arXiv:2103.14024 \[cs\]*, Aug. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2103.14024>. \[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[12\] </span><span
class="csl-right-inline">B. Mildenhall, P. P. Srinivasan, M. Tancik, J.
T. Barron, R. Ramamoorthi, and R. Ng, “NeRF: Representing Scenes as
Neural Radiance Fields for View Synthesis,” in *Computer Vision – ECCV
2020*, 2020, pp. 405–421, doi: [gj826m](https://doi.org/gj826m). </span>

<span class="csl-left-margin">\[13\] </span><span
class="csl-right-inline">A. Yu, V. Ye, M. Tancik, and A. Kanazawa,
“<span class="nocase">pixelNeRF</span>: Neural Radiance Fields From One
or Few Images,” 2021, pp. 4578–4587 \[Online\]. Available:
<https://openaccess.thecvf.com/content/CVPR2021/html/Yu_pixelNeRF_Neural_Radiance_Fields_From_One_or_Few_Images_CVPR_2021_paper.html>.
\[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[14\] </span><span
class="csl-right-inline">R. Martin-Brualla, N. Radwan, M. S. M. Sajjadi,
J. T. Barron, A. Dosovitskiy, and D. Duckworth, “NeRF in the Wild:
Neural Radiance Fields for Unconstrained Photo Collections,” 2021, pp.
7210–7219 \[Online\]. Available:
<https://openaccess.thecvf.com/content/CVPR2021/html/Martin-Brualla_NeRF_in_the_Wild_Neural_Radiance_Fields_for_Unconstrained_Photo_CVPR_2021_paper.html>.
\[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[15\] </span><span
class="csl-right-inline">L. Yen-Chen, P. Florence, J. T. Barron, A.
Rodriguez, P. Isola, and T.-Y. Lin, “INeRF: Inverting Neural Radiance
Fields for Pose Estimation,” *arXiv:2012.05877 \[cs\]*, Aug. 2021
\[Online\]. Available: <http://arxiv.org/abs/2012.05877>. \[Accessed:
Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[16\] </span><span
class="csl-right-inline">C. Gao, Y. Shih, W.-S. Lai, C.-K. Liang, and
J.-B. Huang, “Portrait Neural Radiance Fields from a Single Image,”
*arXiv:2012.05903 \[cs\]*, Apr. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2012.05903>. \[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[17\] </span><span
class="csl-right-inline">C.-H. Lin, W.-C. Ma, A. Torralba, and S. Lucey,
“BARF: Bundle-Adjusting Neural Radiance Fields,” *arXiv:2104.06405
\[cs\]*, Aug. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2104.06405>. \[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[18\] </span><span
class="csl-right-inline">K. Zhang, G. Riegler, N. Snavely, and V.
Koltun, “NeRF++: Analyzing and Improving Neural Radiance Fields,”
*arXiv:2010.07492 \[cs\]*, Oct. 2020 \[Online\]. Available:
<http://arxiv.org/abs/2010.07492>. \[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[19\] </span><span
class="csl-right-inline">C. Reiser, S. Peng, Y. Liao, and A. Geiger,
“KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny
MLPs,” *arXiv:2103.13744 \[cs\]*, Aug. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2103.13744>. \[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[20\] </span><span
class="csl-right-inline">D. Rebain, W. Jiang, S. Yazdani, K. Li, K. M.
Yi, and A. Tagliasacchi, “DeRF: Decomposed Radiance Fields,” 2021, pp.
14153–14161 \[Online\]. Available:
<https://openaccess.thecvf.com/content/CVPR2021/html/Rebain_DeRF_Decomposed_Radiance_Fields_CVPR_2021_paper.html>.
\[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[21\] </span><span
class="csl-right-inline">J. T. Barron, B. Mildenhall, M. Tancik, P.
Hedman, R. Martin-Brualla, and P. P. Srinivasan, “Mip-NeRF: A Multiscale
Representation for Anti-Aliasing Neural Radiance Fields,”
*arXiv:2103.13415 \[cs\]*, Aug. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2103.13415>. \[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[22\] </span><span
class="csl-right-inline">P. Hedman, P. P. Srinivasan, B. Mildenhall, J.
T. Barron, and P. Debevec, “Baking Neural Radiance Fields for Real-Time
View Synthesis,” *arXiv:2103.14645 \[cs\]*, Mar. 2021 \[Online\].
Available: <http://arxiv.org/abs/2103.14645>. \[Accessed: Sep. 25,
2021\]</span>

<span class="csl-left-margin">\[23\] </span><span
class="csl-right-inline">Z. Wang, S. Wu, W. Xie, M. Chen, and V. A.
Prisacariu, “NeRF–: Neural Radiance Fields Without Known Camera
Parameters,” *arXiv:2102.07064 \[cs\]*, Feb. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2102.07064>. \[Accessed: Sep. 25, 2021\]</span>

<span class="csl-left-margin">\[24\] </span><span
class="csl-right-inline">J. Li, Z. Feng, Q. She, H. Ding, C. Wang, and
G. H. Lee, “MINE: Towards Continuous Depth MPI with NeRF for Novel View
Synthesis,” *arXiv:2103.14910 \[cs\]*, Jul. 2021 \[Online\]. Available:
<http://arxiv.org/abs/2103.14910>. \[Accessed: Oct. 11, 2021\]</span>
