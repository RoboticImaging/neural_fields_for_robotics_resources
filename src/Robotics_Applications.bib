
@article{zhu_nice-slam_2021,
	title = {{NICE}-{SLAM}: {Neural} {Implicit} {Scalable} {Encoding} for {SLAM}},
	journal = {arXiv},
	author = {Zhu, Zihan and Peng, Songyou and Larsson, Viktor and Xu, Weiwei and Bao, Hujun and Cui, Zhaopeng and Oswald, Martin R. and Pollefeys, Marc},
	year = {2021},
}

@article{adamkiewicz_vision-only_2021,
	title = {Vision-{Only} {Robot} {Navigation} in a {Neural} {Radiance} {World}},
	url = {http://arxiv.org/abs/2110.00168},
	abstract = {Neural Radiance Fields (NeRFs) have recently emerged as a powerful paradigm for the representation of natural, complex 3D scenes. NeRFs represent continuous volumetric density and RGB values in a neural network, and generate photo-realistic images from unseen camera viewpoints through ray tracing. We propose an algorithm for navigating a robot through a 3D environment represented as a NeRF using only an on-board RGB camera for localization. We assume the NeRF for the scene has been pre-trained offline, and the robot's objective is to navigate through unoccupied space in the NeRF to reach a goal pose. We introduce a trajectory optimization algorithm that avoids collisions with high-density regions in the NeRF based on a discrete time version of differential flatness that is amenable to constraining the robot's full pose and control inputs. We also introduce an optimization based filtering method to estimate 6DoF pose and velocities for the robot in the NeRF given only an onboard RGB camera. We combine the trajectory planner with the pose filter in an online replanning loop to give a vision-based robot navigation pipeline. We present simulation results with a quadrotor robot navigating through a jungle gym environment, the inside of a church, and Stonehenge using only an RGB camera. We also demonstrate an omnidirectional ground robot navigating through the church, requiring it to reorient to fit through the narrow gap. Videos of this work can be found at https://mikh3x4.github.io/nerf-navigation/ .},
	urldate = {2021-10-11},
	journal = {arXiv:2110.00168 [cs]},
	author = {Adamkiewicz, Michal and Chen, Timothy and Caccavale, Adam and Gardner, Rachel and Culbertson, Preston and Bohg, Jeannette and Schwager, Mac},
	month = sep,
	year = {2021},
	keywords = {â›” No DOI found, Computer Science - Robotics},
	annote = {ZSCC: 0000000 arXiv: 2110.00168},
	file = {arXiv Fulltext PDF:/home/jack/Zotero/storage/GMSQPRWH/Adamkiewicz et al. - 2021 - Vision-Only Robot Navigation in a Neural Radiance .pdf:application/pdf;arXiv.org Snapshot:/home/jack/Zotero/storage/EBYTKNHK/2110.html:text/html},
}

@inproceedings{sucar_imap_2021,
	title = {{iMAP}: {Implicit} {Mapping} and {Positioning} in {Real}-{Time}},
	booktitle = {Proceedings of the {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Sucar, Edgar and Liu, Shikun and Ortiz, Joseph and Davison, Andrew J.},
	month = oct,
	year = {2021},
	pages = {6229--6238},
}
